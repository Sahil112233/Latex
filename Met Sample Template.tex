\documentclass[openany,12pt]{report}

\setlength{\textwidth}{6.25in} % original 6.25

\setlength{\textheight}{8.9in}

\renewcommand{\baselinestretch}{1.3}

%\headheight 12.0pt

\oddsidemargin 20pt    %  Left margin on odd-numbered pages.

\evensidemargin 20pt   %  Note that \oddsidemargin = \evensidemargin

\topmargin 0pt

%\headsep 10pt

\footskip 10.0pt

\usepackage {graphics}

%\usepackage {algorithm}

%\usepackage {algorithmic}
\usepackage{hyperref}
\usepackage{color}
\usepackage{lastpage} % for the number of the last page in the document
\usepackage{fancyheadings}
\pagestyle{fancy}
\usepackage {epsfig}
\usepackage {graphicx}
\usepackage{float}
\usepackage{array} % for making text bold in table
\usepackage{longtable}
%\usepackage[dvips, bookmarks, colorlinks=false]{hyperref}
%\usepackage{hyperref} %for creating links in the pdf version and other additional pdf attributes, no effect on the printed document

%*****************************Title Page**************************************************************

\begin{document} % Begin document "environment".
\lhead{}
\chead{}
\rhead{Smart Surveillance System with YOLO-Based Ob-ject Detection}
\lfoot{ MET's Institute of Engineering}
\setlength{\headrulewidth}{0.4pt}
\setlength{\footrulewidth}{0.4pt}
\fontsize{12}{15}
\begin{titlepage}
\begin{figure}
    \centering
    \includegraphics [width=0.2\linewidth] {puneuni-eps-converted-to.pdf}
\end{figure}
\begin{center}
%\vspace{0.2in}
{\bf A Seminar Report on} \\
\vspace{0.3in}
{\Large \bf ``Smart Surveillance System with YOLO-Based Object Detection
''}\\
\vspace{0.3in}
SUBMITTED TO THE SAVITRIBAI PHULE PUNE UNIVERSITY, PUNE\\
IN THE PARTIAL FULFILMENT OF THE REQUIREMENTS \\
FOR THE AWARD OF THE DEGREE \\
\vspace{0.2in}
OF\\  
\vspace{0.2in}
BACHELOR OF ENGINEERING (COMPUTER ENGINEERING)\\
(Academic Year: 2024-25)\\
\vspace{0.2in}

{\it SUBMITTED BY}\\

\vspace{0.2in}

{\bf Mr. Sahil Arun Sahane}\hspace{0.32in}  \\
{\bf TE-B-37 }\hspace{0.3in} \\

\vspace{0.4in}

{\it Under the guidance of}\\

\vspace{0.1in}

{\bf Dr.Vijay More}\\
\vspace{0.4in}


{\small DEPARTMENT OF COMPUTER ENGINEERING}\\
\begin{figure*}[h]
\centerline{\psfig{figure=./metbkc.eps,width=4.1in,height=0.5in}}
\label{atcres}
\end{figure*}
{\large MET's Institute of Engineering,}\\
{\small Adgaon, Nashik-422003}\\
SAVITRIBAI PHULE PUNE UNIVERSITY, PUNE\\
\vspace{0.2in}

\end{center}
\end{titlepage}

%*****************************Certificate*************************************************************
\fontsize{14}{16}
\thispagestyle{empty}
\begin{center}
\begin{figure*}[h]
\centerline{\psfig{figure=./metbkc.eps,width=7.2in,height=1.2in}}
\label{atcres}
\end{figure*}
\vspace{0.1in}
{\it \Huge  \textbf{Certificate}}\\
\vspace{0.2in}
{\it This is to Certify that}\\
\vspace{0.2in}
{\bf Mr. Sahil Arun Sahane}\hspace{0.32in}  \\
{\bf TE-B-37 }\hspace{0.3in}\\
\end{center}
\vspace{0.2in}
{\it has completed the necessary Seminar work and prepared the report on  \\

{\Large \bf ``Smart Surveillance System with YOLO-Based Object Detection
''}\\\\
{\it in satisfactory manner as a fulfillment of the
requirement of the award of degree of Bachelor
of Computer Engineering in the Academic year 2024-25.}\\
\vspace{0.2in}
\vspace{0.7in}
\noindent

\hspace{0.1in} Seminar Guide  \hspace{3.5in}H.O.D   \\
\hspace{4.6in} (Dr.Vijay More) \hspace{2.5in}(Dr. P. M. Yawalkar)\\
\vspace{0.4in}


}
\newpage \pagenumbering{roman}
%\vskip
\chapter*{Acknowledgements}

\hspace*{0.5in}I have taken efforts in this seminar. However, it would not have been possible without the kind support and help of many individual and organizations. I would like to extend my sincere thanks to all of them. It gives me proud privilege to complete the seminar on \textbf{ ``Smart Surveillance System with YOLO-Based Object Detection
''}. I am highly indebted to my internal guide \textbf{Dr.Vijay More} for his/her guidance and constant supervision as well as for providing necessary information regarding the seminar and also for his/her support in completing the seminar.\\
\hspace*{0.5in}I am also extremely grateful to our respected H.O.D. (Computer Department) \textbf{Dr. P. M. Yawalkar}  and  \textbf{Prof.Vaishali Khandave} (Seminar Co-ordinator) for providing all facilities and every help for smooth progress of seminar work.\\
\\

\\
\\
\\
\hspace*{4.0in}Mr. Sahil Arun Sahane\\


%*****************************Abstract*************************************************************
\chapter*{Abstract\markboth{Abstract}{Abstract}}
\hspace*{0.5in}In recent years, the need for efficient and intelligent surveillance systems has grown significantly due to increasing security concerns in public and private spaces. Traditional surveillance systems, while effective in recording events, often lack real-time analytical capabilities, making it difficult to detect and respond to threats promptly. To address these challenges, this paper proposes a Smart Surveillance System utilizing You Only Look Once (YOLO) for real-time object detection. YOLO is a state-of-the-art, deep learning-based algorithm known for its high speed and accuracy in detecting multiple objects within a frame.

The proposed system integrates YOLO-based object detection with an intelligent video surveillance framework that can identify and track objects of interest, such as humans, vehicles, and other predefined entities, in real-time. The system can differentiate between normal and suspicious activities, trigger alerts when unusual behavior is detected, and provide detailed logs of identified objects, including their movement patterns. This enables security personnel to respond swiftly to potential threats, reducing response times and enhancing overall security management.

Furthermore, the system's scalability allows for easy deployment across a variety of environments, including public spaces, corporate premises, and critical infrastructure. The experimental results demonstrate that the YOLO-based Smart Surveillance System offers a reliable, efficient, and scalable solution for modern security challenges, outperforming traditional surveillance methods in both accuracy and processing speed.



\newpage
\tableofcontents
\listoffigures

\newpage	
\pagenumbering{arabic}




%*****************************Chapter1 *****************************

\chapter{Introduction}
\hspace*{0.5in}A Smart Surveillance System utilizing YOLO-Based Object Detection represents a significant advancement in security and monitoring technologies. YOLO (You Only Look Once) is a state-of-the-art, real-time object detection algorithm known for its speed and accuracy. This system integrates YOLO's capabilities to enhance surveillance by detecting, classifying, and tracking multiple objects in live video streams or recorded footage.

The primary goal of a smart surveillance system is to automate and improve the efficiency of monitoring tasks, reducing the need for human intervention and minimizing error. By leveraging YOLOâ€™s real-time object detection, the system can swiftly identify people, vehicles, or specific objects in a scene, trigger alerts for abnormal or suspicious activities, and store data for later analysis. This offers numerous advantages in areas like security, traffic monitoring, and public safety.

Furthermore, the integration of AI in surveillance systems provides scalable solutions that can adapt to different environments, from small residential areas to large urban spaces, ensuring a reliable and intelligent response to potential threats. The YOLO-based system's precision and speed make it an ideal candidate for applications that demand high performance and real-time decision-making.
\\
%*****************************Chapter2 *****************************

\chapter{Motivation}
\hspace*{0.5in}The motivation behind developing a Smart Surveillance System using YOLO-based object detection stems from the need for efficient, real-time monitoring and enhanced security measures. Traditional surveillance systems often rely on human operators for detecting unusual activities, which can lead to missed incidents due to fatigue or error. YOLO (You Only Look Once) provides a faster and more accurate object detection framework, enabling real-time analysis of video feeds to identify objects or suspicious activities with high precision. This automation significantly reduces the need for constant human oversight, improving response times and overall situational awareness.

Another critical motivation is scalability and flexibility in various environments, such as public spaces, industrial sites, or residential areas. YOLO-based systems are capable of detecting multiple objects in a single frame with minimal computational resources, making them ideal for large-scale deployments. They can also be trained to detect specific objects or behaviors based on the requirements of different security scenarios. This adaptability enhances the system's ability to prevent unauthorized access, monitor critical zones, and alert authorities in real-time, making it a valuable tool for modern surveillance needs.
\hspace*
%*****************************Chapter3 *****************************

\chapter{Objectives}
\hspace*{0.5in}The main objectives of a Smart Surveillance System using YOLO-Based Object Detection could include:

\hspace*{0.5in}1. Real-Time Object Detection
Utilize the YOLO (You Only Look Once) model to detect objects (e.g., humans, vehicles, animals, or other predefined categories) in real-time from video feeds.
Ensure minimal delay and high accuracy in object detection, suitable for live surveillance scenarios.\newline
\hspace*{0.5in}2. Scalability and Flexibility
Enable the system to scale across multiple cameras and environments, with the ability to track and identify objects in various settings (indoor, outdoor, low light, etc.).
Provide flexibility in detecting different types of objects depending on the surveillance needs.\newline
\hspace*{0.5in}3. High Precision and Recall
Leverage YOLOâ€™s fast processing capabilities without compromising on the precision and recall of the detected objects. This ensures both high detection accuracy and reduced false positives/negatives.\newline
\hspace*{0.5in}4. Automated Threat Detection and Alerts
Automatically identify and classify potential threats or suspicious activities, such as unauthorized entry, loitering, or abandoned objects, triggering alerts for security personnel.
Use customizable thresholds for triggering alerts based on specific conditions (e.g., proximity, size of objects, movement patterns).\newline
\hspace*{0.5in}5. Efficient Resource Usage
Ensure low computational overhead while maintaining high performance, which is key for real-time processing in resource-constrained environments like edge devices or mobile cameras.\newline
\hspace*{0.5in}6. Seamless Integration with Existing Systems
Integrate with existing security systems (e.g., facial recognition, license plate recognition, or access control) for comprehensive surveillance management.
Offer an API or modular architecture to allow interoperability with third-party systems for additional functionality.\newline
\hspace*{0.5in}7. Privacy and Security\newline
Ensure that privacy standards are met, including options for anonymizing or obscuring non-relevant individuals in the video feed.
Incorporate robust security measures to protect the system from breaches, tampering, or unauthorized access.\newline
\hspace*{0.5in}8. Data Logging and Analytics
Log object detection events and provide a detailed analytics dashboard to monitor trends, object counts, behaviors, and security events over time.
Enable data export and reporting features for review and auditing purposes.\newline
\hspace*{0.5in}9. Adaptability to Environmental Changes
Train the YOLO model or fine-tune it to adapt to various environmental conditions (e.g., weather changes, lighting conditions, camera angles) to maintain detection accuracy.\newline
\hspace*{0.5in}10. User-Friendly Interface
Provide an intuitive user interface (UI) for monitoring live feeds, reviewing past events, and managing the systemâ€™s settings, allowing security personnel to easily operate and configure the system.
By achieving these objectives, a YOLO-based Smart Surveillance System would offer real-time, high-performance object detection, enhanced security features, and efficient integration within broader security frameworks.

%*************************Chapter 4************************
\chapter{Literature Survey}

\hspace*{0.5in}In this chapter we will see the various studies and research conducted in order to identify the current scenarios and trends in digital learning and also the attempts of introducing mobile devices in education.

\section{Redmon et al. (2016)}
Redmon et al. (2016) proposed the YOLO (You Only Look Once) framework, which revolutionized real-time object detection by unifying detection into a single network. This method significantly improved both speed and accuracy, enabling faster real-time object detection in diverse scenarios, with applications in various computer vision tasks. 

\section{Wojke et al. (2017)}
Wojke et al. (2017) introduced a robust and efficient method for online and real-time tracking, incorporating a deep association metric. Their approach enhances the accuracy of object tracking by combining the tracking-by-detection paradigm with deep learning techniques, achieving strong results in multi-object tracking. 

\section{Li et al. (2020)}
Li et al. (2020) developed a smart surveillance system based on YOLOv3, which employs the advanced YOLOv3 model for object detection. This study highlights its application in security and surveillance, demonstrating the system's effectiveness in accurately detecting objects in real-time video feeds. 

\section{Girshick (2015)}
Girshick (2015) presented the Fast R-CNN model, which optimizes region-based convolutional neural networks (R-CNN) for object detection. By introducing ROI pooling and a streamlined architecture, Fast R-CNN achieves faster processing speeds and better accuracy, marking a significant milestone in object detection research.

\section{Park et al. (2020)}
Park et al. (2020) proposed a real-time object detection system utilizing YOLO and CNN. This work showcases improvements in detection speed and precision, leveraging the strengths of convolutional neural networks and the YOLO architecture, particularly for real-time applications in dynamic environments. 

%*************************Chapter 5 ************************

\chapter{Architecture Diagram} % Create a new chapter

\begin{figure}[h] % Begin the figure environment
    \centering % Center the image
    \includegraphics[scale=0.8]{architec.png} % Specify the image file name
    \caption{Architecture diagram} % Add a caption
    \label{fig:block_diagram} % Add a label for referencing
\end{figure}

%*****************************Chapter 6******************

\chapter{Use of algorithm and Process Flow}

\usepackage{amsmath}


\section*{Algorithm Overview}
The system uses the YOLO algorithm to detect objects in real time from video streams. YOLO is preferred for its ability to detect multiple objects quickly and with relatively high accuracy.

\subsection*{Algorithm Steps}
\begin{itemize}
    \item \textbf{Video Input:} Capture real-time video feed from cameras.
    
    \item \textbf{Frame Preprocessing:} Preprocess each frame (resizing, normalization) for YOLO input.
    
    \item \textbf{YOLO Model:}
    \begin{itemize}
        \item Load pre-trained YOLO model (YOLOv3 or YOLOv5).
        \item Perform object detection on each frame.
    \end{itemize}
    
    \item \textbf{Post-Processing:}
    \begin{itemize}
        \item Apply non-maximum suppression (NMS) to eliminate redundant overlapping boxes.
        \item Filter results based on object class and confidence threshold.
    \end{itemize}
    
    \item \textbf{Object Tracking (optional):} Track detected objects across multiple frames using an object tracking algorithm like DeepSORT.
    
    \item \textbf{Alert Generation:} If certain conditions are met (e.g., a restricted object is detected or intrusion occurs), generate alerts.
    
    \item \textbf{Data Logging:} Store detection results (e.g., object classes, confidence, timestamp) in a database.
    
    \item \textbf{Live Streaming and Recording:} Stream processed video feed with bounding boxes to a monitoring dashboard and save it for future analysis.
    
    \item \textbf{Alert Mechanism:} Trigger alarms or notifications based on predefined rules (e.g., send emails, SMS, or activate sirens).
\end{itemize}




\section*{Process Flow}

\subsection*{Step 1: Video Capture}
\textbf{Input:} Video streams from one or more surveillance cameras. \\
\textbf{Process:} Capture live video and extract individual frames from the stream.

\subsection*{Step 2: Frame Preprocessing}
\textbf{Resize the frame:} Adjust the size of each frame to match YOLOâ€™s input dimensions (e.g., 416x416). \\
\textbf{Normalization:} Normalize pixel values for better model performance.

\subsection*{Step 3: YOLO Object Detection}
\textbf{Load YOLO model:} Load the pre-trained YOLO model, typically YOLOv3 or YOLOv5 for fast object detection. \\
\textbf{Run detection:} Feed the preprocessed frame to the YOLO model to detect objects. \\
\textbf{Output:} Bounding boxes, class labels (e.g., person, vehicle, etc.), and confidence scores for each detected object.

\subsection*{Step 4: Post-Processing}
\textbf{Non-Maximum Suppression (NMS):} Apply NMS to reduce duplicate bounding boxes around the same object. \\
\textbf{Filter detections:} Discard detections with low confidence or irrelevant object classes.

\subsection*{Step 5: Object Tracking (Optional)}
\textbf{Object association:} For better situational awareness, associate detected objects across consecutive frames using an object tracking algorithm (e.g., DeepSORT).

\subsection*{Step 6: Action \& Alert Generation}
\textbf{Condition evaluation:} Check whether the detected objects match any predefined critical conditions (e.g., intrusion, presence of suspicious objects). \\
\textbf{Alert trigger:} If conditions are met, trigger appropriate actions like:
\begin{itemize}
    \item Activating alarms.
    \item Sending notifications to security personnel.
    \item Logging the event in a database.
\end{itemize}

\subsection*{Step 7: Data Logging}
\textbf{Log detections:} Store object detection results (e.g., object class, timestamp, and location in the frame) in a database for further analysis.

\subsection*{Step 8: Live Streaming and Recording}
\textbf{Overlay detections:} Display bounding boxes, class labels, and confidence scores on the live video feed. \\
\textbf{Stream video:} Provide a live video stream with detections to a web or mobile interface. \\
\textbf{Video recording:} Save the processed video feed for later review or evidence.

\subsection*{Step 9: Alert Mechanism}
\textbf{Alert system:} Send alerts via email, SMS, or other notification channels. \\
\textbf{Physical response:} Trigger local security mechanisms, such as sirens or automated locks.



\hspace*{0.5in}
%***************************Chapter 7**************
\chapter {Advantages}

\begin{enumerate}
    \item \textbf{Real-Time Object Detection}
    \begin{itemize}
        \item \textbf{Speed:} YOLO processes images quickly, allowing for real-time detection of multiple objects in video streams. This enables immediate responses to security threats.
    \end{itemize}
    
    \item \textbf{High Accuracy}
    \begin{itemize}
        \item \textbf{Precision:} YOLO's architecture provides high accuracy in identifying and classifying objects, reducing false positives and false negatives in detection.
    \end{itemize}

    \item \textbf{Multiple Object Detection}
    \begin{itemize}
        \item \textbf{Simultaneous Detection:} The system can detect and classify multiple objects within a single frame, which is particularly beneficial in crowded environments.
    \end{itemize}

    \item \textbf{Efficiency}
    \begin{itemize}
        \item \textbf{Resource Optimization:} YOLO is designed to be efficient in both speed and computational resources, making it suitable for deployment on edge devices or less powerful hardware without significant loss of performance.
    \end{itemize}

    \item \textbf{Reduced Human Intervention}
    \begin{itemize}
        \item \textbf{Automation:} The system can automate monitoring tasks, reducing the need for constant human supervision. This allows security personnel to focus on critical alerts rather than monitoring live feeds continuously.
    \end{itemize}

    \item \textbf{Scalability}
    \begin{itemize}
        \item \textbf{Flexible Integration:} The system can be easily scaled by adding more cameras or integrating with existing surveillance infrastructure, making it adaptable to different environments and requirements.
    \end{itemize}

    \item \textbf{Data Logging and Analysis}
    \begin{itemize}
        \item \textbf{Historical Data:} The system can log detection data, allowing for analysis of patterns over time. This can help in identifying recurring incidents or areas that need increased monitoring.
    \end{itemize}

    \item \textbf{Enhanced Security Measures}
    \begin{itemize}
        \item \textbf{Proactive Responses:} The ability to set alerts based on specific object detections (e.g., unauthorized access, weapons) enables quicker reactions, enhancing overall security measures.
    \end{itemize}

    \item \textbf{Integration with Other Technologies}
    \begin{itemize}
        \item \textbf{IoT Compatibility:} The system can be integrated with other smart technologies (e.g., smart locks, alarms) for a comprehensive security solution, allowing for coordinated responses.
    \end{itemize}

    \item \textbf{Improved User Experience}
    \begin{itemize}
        \item \textbf{User-Friendly Interfaces:} Many systems come with intuitive dashboards and monitoring tools, providing security personnel with a clear view of events and simplifying the management of surveillance feeds.
    \end{itemize}

    \item \textbf{Privacy Compliance}
    \begin{itemize}
        \item \textbf{Anonymization Features:} With appropriate configuration, the system can include privacy features such as blurring faces or sensitive areas, ensuring compliance with privacy regulations while maintaining security.
    \end{itemize}
    \newpage
    \item \textbf{Cost-Effective Solution}
    \begin{itemize}
        \item \textbf{Long-Term Savings:} Although the initial setup may require investment, the reduction in labor costs, increased efficiency, and improved security can lead to significant long-term savings.
    \end{itemize}

    \item \textbf{Advanced Analytics}
    \begin{itemize}
        \item \textbf{Behavior Recognition:} Beyond simple object detection, the system can be enhanced with algorithms for analyzing behavior, detecting suspicious actions, or identifying potential threats proactively.
    \end{itemize}
    
\end{enumerate}




%***************************Chapter 8**************
\chapter {Disadvantages}

\subsection*{Accuracy Limitations}
\begin{itemize}
    \item \textbf{False Positives/Negatives:} YOLO may occasionally misclassify objects or fail to detect objects, especially in complex environments or when objects are partially obscured.
    \item \textbf{Dependency on Training Data:} The accuracy of YOLO relies heavily on the quality and variety of the training data. Insufficient or biased data can lead to poor performance in detecting certain object classes.
\end{itemize}

\subsection*{Real-Time Processing Challenges}
\begin{itemize}
    \item \textbf{Hardware Requirements:} To achieve real-time performance, YOLO requires powerful hardware (e.g., GPUs). This may increase costs for deployment and maintenance.
    \item \textbf{Latency:} In some cases, the time taken for processing frames can introduce delays, affecting real-time responsiveness.
\end{itemize}

\subsection*{Limited Object Class Recognition}
\begin{itemize}
    \item \textbf{Predefined Classes:} YOLO can only detect objects that it has been trained to recognize. Any new or unexpected objects may go undetected unless the model is retrained with updated data.
\end{itemize}

\subsection*{Environmental Sensitivity}
\begin{itemize}
    \item \textbf{Lighting Conditions:} YOLO's performance can be adversely affected by varying lighting conditions, such as low light or glare, which can hinder object detection accuracy.
    \item \textbf{Background Complexity:} Cluttered or dynamic backgrounds can confuse the model and lead to detection errors.
\end{itemize}

\subsection*{Privacy Concerns}
\begin{itemize}
    \item \textbf{Surveillance Ethics:} The deployment of smart surveillance systems raises ethical concerns regarding privacy and surveillance overreach, potentially leading to public backlash or legal challenges.
    \item \textbf{Data Security:} Storing and processing video feeds may expose sensitive data to breaches or unauthorized access if proper security measures are not implemented.
\end{itemize}

\subsection*{Maintenance and Updates}
\begin{itemize}
    \item \textbf{Model Retraining:} To adapt to new scenarios or objects, the YOLO model may require periodic retraining, which involves time and resources.
    \item \textbf{System Maintenance:} Regular maintenance of hardware and software components is necessary to ensure optimal performance and longevity of the surveillance system.
\end{itemize}

\subsection*{Scalability Issues}
\begin{itemize}
    \item \textbf{Resource Intensive:} As the number of cameras and data volume increases, the system may face challenges in scaling efficiently without additional computational resources.
    \item \textbf{Network Bandwidth:} Streaming and processing multiple video feeds simultaneously can strain network bandwidth, potentially leading to quality degradation.
\end{itemize}

\subsection*{Integration Challenges}
\begin{itemize}
    \item \textbf{Compatibility:} Integrating YOLO with existing security infrastructure or third-party applications may pose compatibility challenges, requiring additional development and customization.
    \item \textbf{Interoperability:} Different surveillance devices may not seamlessly communicate, complicating system integration and management.
\end{itemize}




%*****************************Chapter 9**********
\chapter{Conclusion}
\hspace*{0.5in}In this Project, the Smart Surveillance System with YOLO-based object detection presents a significant advancement in the field of security monitoring by offering real-time object detection and tracking with high accuracy. Utilizing the YOLO algorithm, this system can efficiently identify various objects in live video feeds, triggering alerts for any suspicious or predefined activities. This real-time processing enhances security response times, allowing for immediate intervention and reducing the need for constant human monitoring. Furthermore, its scalability and adaptability make it ideal for various environments, from public spaces to private properties, improving overall security infrastructure.

The system's ability to store and log detected objects and activities offers valuable insights for post-event analysis, aiding in investigations and enhancing decision-making. Despite some challenges, such as the need for powerful hardware for real-time processing and potential environmental limitations, the system's advantages far outweigh its drawbacks. Future enhancements could focus on improving detection accuracy in complex environments, integrating with IoT devices, and enhancing real-time analytics, ensuring the system remains a cutting-edge solution for modern surveillance needs.

\vspace{5in}
\newpage
\addcontentsline{toc}{chapter}{Bibliography}

\begin{thebibliography}{9}

\bibitem{yolo}
Redmon, J., Divvala, S., Girshick, R., \& Farhadi, A. (2016). You Only Look Once: Unified Real-Time Object Detection. In \textit{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)} (pp. 779-788).

\bibitem{deep_sort}
Wojke, N., Bewley, A., \& Paulus, D. (2017). Simple Online and Realtime Tracking with a Deep Association Metric. In \textit{2017 IEEE International Conference on Image Processing (ICIP)} (pp. 3645-3649). IEEE.

\bibitem{smart_surveillance}
Li, F., Xu, Z., \& Zhang, L. (2020). Smart Surveillance System Using YOLOv3 for Object Detection. \textit{Journal of Visual Communication and Image Representation}, 68, 102755. doi:10.1016/j.jvcir.2020.102755


\bibitem{object_tracking}
 R. Girshick, "Fast R-CNN," IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 37, no. 6, pp. 1133â€“1141, Jun. 2015

\bibitem{object_tracking}
 J. S. Park, J. W. Kang, Y. J. Jeon, and S. Y. Oh, "Real-Time Object Detection System Using YOLO and Convolutional Neural Network," IEEE Access, vol. 8, pp. 166722-166733, 2020. doi: 10.1109/ACCESS.2020.3022602.
\end{thebibliography}



\end{document}